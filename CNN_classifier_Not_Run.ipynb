{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "CNN_classifier- Not Run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA6L3sZw2v8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras as k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfRL3teL2v8y",
        "colab_type": "text"
      },
      "source": [
        "# Train a Convolutional Neural Network to Classify MNIST\n",
        "\n",
        "**Why not just rearrange our image as a big long vector and use a normal neural network?**\n",
        "Usually features in an image are spread over neigbouring pixels, if we scan a 2D image with a filter then we'll capture those clustered features which might be missed when reshaping the image into a long vector.\n",
        "\n",
        "1. Load data\n",
        "2. Define model\n",
        "3. Train model\n",
        "4. Evaluate who well it performs\n",
        "5. Use the model on our own data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGJCK_5w2v8z",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imVhzYL-2v8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = k.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLFO_ZeC2v81",
        "colab_type": "text"
      },
      "source": [
        "Let's look at what we just loaded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMInTgCi2v82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('x_train: {}'.format(x_train.shape),\n",
        "      'y_train: {}'.format(y_train.shape),\n",
        "      'x_test: {}'.format(x_test.shape),\n",
        "      'y_test: {}'.format(y_test.shape)\n",
        "     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzm1_TG2v84",
        "colab_type": "text"
      },
      "source": [
        "``x_train`` - We have 60,000 (28x28) images of handwritten digits to train the classifier.\n",
        "\n",
        "``y_train`` - There are 60,000 corresponding labels which tell us which number is represented in the image.\n",
        "\n",
        "``x_test`` - These 10,000 images are not used for training. We'll keep these to test how good our model is at predicting the number in some **unseen** images.\n",
        "\n",
        "``y_test`` - Corresponding labels for the x_test images. We'll use these as a ground truth to check how many of the test images our model guessed correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux3mTEGV2v84",
        "colab_type": "text"
      },
      "source": [
        "Lets have a look at the first 25 images in the training set, we'll use the ``y_train`` labels as titles to the images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuIUkGZS2v85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x_train[i,:,:])\n",
        "    plt.title('{}'.format(y_train[i]))\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD5ZeOi82v87",
        "colab_type": "text"
      },
      "source": [
        "# 2. Define a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ax8IGCo2v87",
        "colab_type": "text"
      },
      "source": [
        "First we need to use tensorflow to make a network, we'll call it ``model``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85UqnuDX2v87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = k.Sequential([\n",
        "    Conv2D(20, (3,3), padding='same', activation=tf.nn.relu, \n",
        "           input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2), strides=2),\n",
        "    Conv2D(40, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    MaxPooling2D((2, 2), strides=2),\n",
        "    Flatten(),    \n",
        "    Dense(80, activation=tf.nn.relu),\n",
        "    Dense(10,  activation=tf.nn.softmax)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb3uWRk22v89",
        "colab_type": "text"
      },
      "source": [
        "### Let's break it down:\n",
        "\n",
        "Model specs:\n",
        "- ``Sequential`` So that each layer will pass into the next layer \n",
        "- ``Conv2D`` The 1st layer is has ``20`` ``(3,3)`` convolutional filters (sometimes referred to as kernels) which will each scan over our image like this: <br>\n",
        "<center><img src=\"https://miro.medium.com/max/790/1*1okwhewf5KCtIPaFib4XaA.gif\" width=\"200\" align=\"center\">\n",
        "<center><em>The image (blue), is scanned with a (3x3) filter (grey) and the output <br>of each of the filters will produce 20 feature maps of the image (green).</em></center>\n",
        "<br>\n",
        "- ``padding`` Notice that there needs to be padding added around our image for the scan to work at the edges. Using the ``same`` argument will make sure that our feature maps are the same size as our input image to the layer.\n",
        "- ``activation`` All our 20 feature maps have 28x28 pixels. Each feature map has a weight which will multiply all the pixels by the same number, this is a learned weight because some maps will more important for the task than others. Then all the feature maps are summed pixel-wise and each pixel will act as a node with an activation function. In this case the simple but very effective non-linear ``relu`` function (below).\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/2052/1*DfMRHwxY1gyyDmrIAd-gjQ.png\" width=\"400\" align=\"center\"></center>\n",
        "\n",
        "- ``input_shape`` This will be the dimensions of our image. Notice we added an extra dimension on the end, this is because the model will eventually store all the feature maps in this dimension so we'll need to add a dimension to our training and test input data. Luckily there's an easy way to do that: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FDMnFhi2v8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print('x_train: {}'.format(x_train.shape))\n",
        "print('x_test : {}'.format(x_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llG7CGXy2v9C",
        "colab_type": "text"
      },
      "source": [
        "- ``MaxPooling`` - The 2nd layer in our model is a dimensionality reduction. This scans a filter with shape ``(2,2)``over the output from the ``Conv2D`` layer and simply takes the maximum value of every step to be the downsampled pixel value. The ``strides`` argument just tells the filter how many pixels to step along during the scan. \n",
        "\n",
        "<center><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/Figure_4-87c227113cdd0b73d842267404d4aa00.gif\" width=\"400\"></center>\n",
        "\n",
        "<center><em>Max-pooling by scanning a 2x2 filter in strides of 2 pixels to <br>downsample the output of the previous layer</em></center>\n",
        "\n",
        "- The next layer doubles the number of filters and feature maps to ``40`` and downsamples the image size again with another ``MaxPooling`` layer. Usually the first layer will capture basic features such as edges and fundamental shapes in the input, as we progress through the layers, there are a lot more features we're looking for which are more complex and intricate, this is why the number of filters is increased.\n",
        "\n",
        "- ``Flatten`` The 5th layer in the model will take the output of layer 4 and arrange it as a long 1D vector so we can use a fully connected neural network to do the classification task.\n",
        "- ``Dense`` The penultimate layer will use 80 fully connected neurons and the output of the convolutional feature extraction and learn which features correspond to the labels.\n",
        "- ``softmax`` Notice that we're using a different activation function in the final layer, this will normalise all the outputs to sum=1 so we get a **probability** of being each class instead of looking for the largest number.\n",
        "- You should also take note that we only have 10 nodes in the last layer, we can't really change this because there are only 10 different options in our labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkeCAKd72v9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('labels --> [{},{}]'.format(y_train.min(), y_train.max()))\n",
        "\n",
        "# plot the labels as a histogram to visualise 10 different possibilities\n",
        "hist = np.histogram(y_train, bins=np.arange(11))\n",
        "plt.bar(hist[1][:-1], hist[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8VvjkQ72v9E",
        "colab_type": "text"
      },
      "source": [
        "### Get tensorflow to summarise what we've built (great for trouble shooting errors!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXg28bZV2v9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ7TK8Zc2v9G",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_i5f402v9G",
        "colab_type": "text"
      },
      "source": [
        "### First we need to compile the model and choose the hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlDNBCzm2v9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "             )\n",
        "print('Compiled! Ready to start training..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKzmSvnj2v9I",
        "colab_type": "text"
      },
      "source": [
        " - ``optimizer`` We're using gradient descent so the step we take in the gradient direction on each iteration needs to be determined. In this case we're using a technique developed in http://arxiv.org/abs/1412.6980 to efficiently solve the problem. There are lots of optimizers to try:\n",
        "     - Adadelta\n",
        "     - Adagrad\n",
        "     - Adam\n",
        "     - Adamax\n",
        "     - Nadam\n",
        "     - RMSprop\n",
        "     - SGD\n",
        "     \n",
        " - ``loss`` This is the objective function we're minimising. using ``sparse_categorical_crossentropy`` will compare the probability outcome of our model with the real result to minimise the difference in pobability distribution. The sparse part is just because our ``y_train`` and ``y_test`` data is integers rather than how the output nodes are arranged as a string of ones and zeros.\n",
        " \n",
        " - ``metrics`` We want to monitor how well the model is doing and ``['accuracy']`` will report the percentage of correct predictions as an output when we're training and testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsBdSBOK2v9J",
        "colab_type": "text"
      },
      "source": [
        "### Train the model with the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uN26kzV2v9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          epochs=10,\n",
        "          batch_size=30,\n",
        "          shuffle='True'\n",
        "         )\n",
        "\n",
        "# If running this on Google Colab then go to:\n",
        "# \"Runtime\" -> \"Change Runtime Type\" -> \"GPU\"\n",
        "# to speed things up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTgy1PFj2v9L",
        "colab_type": "text"
      },
      "source": [
        "- ``epochs`` The number of times the entire training data is passed throught the model\n",
        "- ``batch_size`` Calculating the gradient for the entire 60,000 training images and labels at once is computationally expensive, so we break it up into chunks of 30 instead. Calculating the gradient 2,000 times on chunks of 30 is much quicker and we can optimise the computer hardware to accelerate the training.\n",
        "- ``shuffle`` The training set is already shuffled in our case so that we don't introduce the images in order as we train. However, the shuffle parameter will re-shuffle the order of the training data on every epoch so that we'll train with different mini-batches every iteration.\n",
        "\n",
        "# 4. Evaluate the model\n",
        "Now we test the performance on our unseen test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8_z9-sG2v9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('loss: {:.3f}, acc: {:.3f}'.format(results[0],results[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFdMZom42v9N",
        "colab_type": "text"
      },
      "source": [
        "- ``evaluate`` Takes all our 10,000 test images and compares the prediction with the ground truth. Our model got 98.3% of the test images correct.\n",
        "\n",
        "Now lets **use** the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elhca3gL2v9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_image = 44\n",
        "\n",
        "predict = model.predict(x_test[example_image:example_image+1])\n",
        "\n",
        "plt.imshow(x_test[example_image,:,:,0])\n",
        "print('Our model guessed: {}'.format(np.argmax(predict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7mvxpbr2v9P",
        "colab_type": "text"
      },
      "source": [
        "Try changing the ``test_image`` variable above to be a number between 0 and 100. \n",
        "\n",
        "In the example above, we're taking the most likely result using the ``np.argmax()`` function but because we trained using ``softmax`` in the output then we can also see the probability of being another class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqU-5JEy2v9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note: Using \\033[1m just makes the text bold\n",
        "print('\\033[1m Here is the full prediction probability\\\n",
        " for all classes:\\033[0m \\n{}'.format(predict))\n",
        "\n",
        "def plot_results(img, prediction):\n",
        "    # Make a subplot showing full prediction\n",
        "    # alongside the example image\n",
        "    \n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.bar(np.arange(10), prediction)\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('Probability')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(img)\n",
        "\n",
        "img = x_test[example_image,:,:,0]\n",
        "prediction = predict[0]\n",
        "\n",
        "plot_results(img, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk1D9Ncw2v9R",
        "colab_type": "text"
      },
      "source": [
        "# 5. Using our own data\n",
        "\n",
        "Let's make our own image and see how well the model predicts the value!\n",
        "\n",
        "Visit: https://jspaint.app/\n",
        "Follow these instructions:\n",
        "- Hit **\"fill\"** and click anywhere on the blank image to make it black\n",
        "- Go to the toolbar at the top and click: **\"Image\" -> \"Attributes\"**\n",
        "- Set size to be **28x28 pixel units** and select **black & white** colours with **opaque** transparency\n",
        "- Hit **\"okay\"**\n",
        "- Back to the toolbar and select: **\"View\" -> \"Zoom\" -> \"Zoom to Window\"\n",
        "- Now select the **Paintbrush** and select the **color white** at the bottom of the screen\n",
        "- Use the left panel to change the brush **size** to be the **smallest**\n",
        "- Draw a number between 0 and 9\n",
        "- **File -> Save** should download the image\n",
        "\n",
        "<center><img src=\"https://github.com/slack-a-jack/ml-getting-started/blob/master/Make%20mnist.gif?raw=true\" width=\"800\" align=\"center\"></center>\n",
        "\n",
        "\n",
        "\n",
        " ### Now upload it using cv2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h76ZK5hM2v9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "# You'll need to use your own file path for your computer!\n",
        "# It will be pretty close to what I've written below\n",
        "filename='C:/Users/jack/Downloads/untitled (1).png'\n",
        "\n",
        "my_img = cv2.imread(filename, 0)\n",
        "\n",
        "plt.imshow(my_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIZfrwb12v9T",
        "colab_type": "text"
      },
      "source": [
        " If it worked, you should see your image!\n",
        " \n",
        " If you get a **\"module not found\"** error here then you need to go to anaconda prompt, activate your environment and type ``conda install opencv``. See the first tutorial on getting stuff downloaded for more info on how to do this)\n",
        " \n",
        " Now we'll use the predict function to see what our classifier thinks it is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfvMtKse2v9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remember we need to have all the correct dimensions\n",
        "my_img_reshaped = np.zeros((1, 28, 28, 1))\n",
        "my_img_reshaped[0,:,:,0] = my_img\n",
        "\n",
        "# the predict function is an array of an array \n",
        "# so that multiple predctions can be made at once.\n",
        "# We only have one prediction here so I've taken the\n",
        "# zeroth element by adding the [0] at the end.\n",
        "predict_my_img = model.predict(my_img_reshaped)[0]\n",
        "\n",
        "plot_results(my_img, predict_my_img)\n",
        "print(predict_my_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkapox6P2v9V",
        "colab_type": "text"
      },
      "source": [
        "### Try draw an image which looks difficult and try and fool the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvENjRcc2v9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You'll need to use your own file path for your computer!\n",
        "# It will be pretty close to what I've written below\n",
        "filename='C:/Users/jack/Downloads/untitled (10).png'\n",
        "my_img = cv2.imread(filename, 0)\n",
        "\n",
        "# Remember we need to have all the correct dimensions\n",
        "my_img_reshaped = np.zeros((1, 28, 28, 1))\n",
        "my_img_reshaped[0,:,:,0] = my_img\n",
        "\n",
        "# the predict function is an array of an array \n",
        "# so that multiple predctions can be made at once.\n",
        "# We only have one prediction here so I've taken the\n",
        "# zeroth element by adding the [0] at the end.\n",
        "predict_my_img = model.predict(my_img_reshaped)[0]\n",
        "\n",
        "plot_results(my_img, predict_my_img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfB7e0Tu2v9X",
        "colab_type": "text"
      },
      "source": [
        "The classifier is more sure that this is the image of an **8** but it assigns some probability to a **5**. Just **one pixel** can make a huge difference because of the filters that we've trained in the model."
      ]
    }
  ]
}